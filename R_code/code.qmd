---
title: "Analysis of Correlated Data (CHL5222H) FInal Project"
subtitle: "Beating the Blues"
author: Group D - Abigail McGrory, Jingxuan He, Martin Ho, Meagan Lacroix, Yanyao Gu 
format: html
---

```{r setup, include=FALSE}
library(here)
library(tidyverse)
library(tinytex)
library(knitr)
library(kableExtra)
library(nlme)
library(texreg)
library(AICcmodavg)

knitr::opts_knit$set(root.dir = here())
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
theme_set(theme_bw(base_size = 15)) # Use black/white theme and increase font size for all ggplot figures
```

```{r}
btb <- read.table(here("data", "btheb.txt"), header = TRUE)
```

```{r}
names(btb)
head(btb)
tail(btb)
```
### Data preparation
```{r}
#add participant ID
btb <- btb %>%
  mutate(id = row_number()) %>%
  select(id, everything())
```

```{r}
#make drug, length, and treatment as factors
btb <- btb %>%
  mutate(
    drug = factor(drug, levels = c("No", "Yes")),  # Set reference level
    length = factor(length, levels = c("<6m", ">6m")),  # Set reference level
    treatment = factor(treatment, levels = c("TAU", "BtheB"))  # Set TAU as reference
  )
```

```{r}
#check structure
str(btb)
```

```{r}
#make data set long
btb.long <- btb %>%
pivot_longer(cols = c("bdi.pre","bdi.2m", "bdi.4m", "bdi.6m", "bdi.8m"),
names_to = "visit",
values_to = "score")%>%
  mutate(
    occasion = case_when(
      visit == "bdi.pre" ~ 0,
      visit == "bdi.2m"  ~ 1,
      visit == "bdi.4m"  ~ 2,
      visit == "bdi.6m"  ~ 3,
      visit == "bdi.8m"  ~ 4))
```


### EDA
```{r}
#make summary table for plotting
btb_summary <- btb.long %>%
  group_by(occasion, treatment, drug, length) %>%
  summarise(
    mean_bdi = mean(score, na.rm = TRUE),
    sd_bdi = sd(score, na.rm = TRUE),
    .groups = "drop")
```

```{r}
#Plot mean BDI score over time by group
ggplot(btb_summary, aes(x = occasion, y = mean_bdi, color = treatment, group = treatment)) +
  geom_line(size = 1) +    # Line plot for mean BDI over time
  geom_point(size = 2) +   # Add points for means
  geom_errorbar(aes(ymin = mean_bdi-sd_bdi, ymax = mean_bdi+sd_bdi), width = 0.2) + # Add 95% CI
  facet_grid(drug ~ length) +  # Panel by drug and length groups
  labs(title = "Mean BDI Score Over Time by Treatment",
       x = "Occasion", y = "Mean BDI Score",
       color = "Treatment Group") +
  theme_minimal() +
  theme(strip.text = element_text(size = 12, face = "bold"))+
  ylim(0, 60) +
  theme(plot.title = element_text(hjust = 0.5))
```

```{r}
#create histogram of the distribution of scores
ggplot(btb, aes(x = bdi.pre)) +
  geom_histogram(binwidth = 5, fill = "steelblue", color = "black", alpha = 0.7) +
  labs(title = "Distribution of BDI Scores Pre-Intervention", x = "BDI Score", y = "Count") +
  theme_minimal() + 
  theme(plot.title = element_text(hjust = 0.5))
```

```{r}
#create histogram of distribution of scores for each treatment group
ggplot(btb, aes(x = bdi.pre)) +
  geom_histogram(binwidth = 5, fill = "steelblue", color = "black", alpha = 0.7) +
  labs(title = "Distribution of BDI Scores Pre-Intervention", x = "BDI Score", y = "Count") +
  theme_minimal() + 
  facet_wrap(~ treatment) +
  theme(plot.title = element_text(hjust = 0.5))
```

```{r}
btb_plot_summary <- btb.long %>%
  group_by(occasion, treatment) %>%
  summarise(mean_score = mean(score, na.rm = TRUE), .groups = "drop")

# Create the plot with trend line for mean values
ggplot(btb.long, aes(x = occasion, y = score, color = treatment)) +
  geom_point(alpha = 0.5) +  # Show individual data points
  geom_line(data = btb_plot_summary, aes(x = occasion, y = mean_score, color = treatment, group = treatment), size = 1.2) +  # Line for mean trend
  labs(title = "BDI Score Trends Over Time", x = "Occasion", y = "BDI Score",
       color = "Treatment") +
  scale_x_continuous(breaks = c(0, 1, 2, 3, 4),  # Specify breaks
                     labels = c("Baseline", "Month 2", "Month 4", "Month 6", "Month 8")) + 
  theme_minimal() +
  ylim(0, 60) +
  theme(plot.title = element_text(hjust = 0.5))

#looks like there is a treatment difference
#looks like they are parallel 
#looks like small time trend, especially at beginning of trial, then it smooths out
#most likely linear
```

```{r}
#spaghetti plot - individual trajectory and a loess smoother
ggplot(btb.long, aes(x = occasion, y = score, group = id, color = factor(treatment))) +
  geom_line(alpha = 0.4) +          # Individual trajectories
  geom_smooth(aes(group = treatment), method = "loess", se = FALSE, linewidth = 1.2) +
  labs(
    x = "Occasion",
    y = "BDI Score",
    color = "Treatment",
    title = "BDI Score Trends Over Time"
  ) +
  scale_x_continuous(breaks = c(0, 1, 2, 3, 4),  
                     labels = c("Baseline", "Month 2", "Month 4", "Month 6", "Month 8"))+ 
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

#spaghetti plot shows high variation between subject BDI scores so we will fit a LMM with 
#random intercept and maybe random slope to account for this variation
```


```{r}
# Summarize counts for Table 1
summary_table <- btb %>%
  group_by(drug, length, treatment) %>%
  summarise(Count = n(), .groups = "drop") %>%
  pivot_wider(names_from = treatment, values_from = Count, values_fill = 0) %>%
  rename("Treatment as Usual" = `TAU`, "Beat the Blues" = `BtheB`) %>%
  mutate(Total = `Treatment as Usual` + `Beat the Blues`) %>%
  rename(Drug = drug, Length = length)

# Compute total row
total_row <- summary_table %>%
  summarise(across(where(is.numeric), sum)) %>%
  mutate(Drug = "Total", Length = "")

# Combine with total row
summary_table <- bind_rows(summary_table, total_row)
```

```{r}
summary_table %>%
  kable(format = "html", caption = "<p style='text-align:center; font-weight:bold;'>
        Table 1. Number of Participants per Treatment Group</p>", align = "c") %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover")) %>%
  add_header_above(c(" " = 2, "Treatment Group" = 3)) 
```

```{r}
btb_summary2 <- btb.long %>%
  group_by(treatment, occasion) %>%
  summarise(
    mean_bdi = mean(score, na.rm = TRUE),
    sd_bdi = sd(score, na.rm = TRUE)
  ) %>%
  mutate(occasion = case_when(
    occasion == 0 ~ "Baseline",
    occasion == 1 ~ "Month 2",
    occasion == 2 ~ "Month 4",
    occasion == 3 ~ "Month 6",
    occasion == 4 ~ "Month 8"
  )) %>%
  ungroup()
```

```{r}
#Table for Mean and SD BDI scores over time by treatment group

# Pivot data to wide format
summary2_wide <- btb_summary2 %>%
  pivot_wider(names_from = treatment, values_from = c(mean_bdi, sd_bdi))
  
#Reorder columns
summary2_wide <- summary2_wide %>%
  select(occasion, `mean_bdi_TAU`, `sd_bdi_TAU`, `mean_bdi_BtheB`, `sd_bdi_BtheB`) %>%
  mutate(across(where(is.numeric), ~round(., 2)))

colnames(summary2_wide) <- c("Occasion", "Mean", "SD", "Mean", "SD")

summary2_wide %>%
  kable(format = "html", caption = "<p style='text-align:center; font-weight:bold;'>
        Mean BDI Scores Over Time by Treatment Group</p>", align = "c") %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover")) %>%
  add_header_above(c(" " = 1, "Treatment as Usual" = 2, "Beat the Blues" = 2))
```

```{r}
ggplot(btb_summary2, aes(x = occasion, y = mean_bdi, color = treatment, group = treatment)) +
  geom_line(size = 1) +    # Line plot for mean BDI over time
  geom_point(size = 2) +   # Add points for means
  geom_errorbar(aes(ymin = mean_bdi - sd_bdi*1.96, ymax = mean_bdi + sd_bdi*1.96), width = 0.2) + # Add 95% CI
  labs(title = "Mean BDI Score Over Time by Treatment",
       x = "Occasion", y = "Mean BDI Score",
       color = "Treatment Group") +
  theme_minimal() +
  theme(strip.text = element_text(size = 12, face = "bold"))+
  theme(plot.title = element_text(hjust = 0.5))
```
```{r}
# empirical covariance and correlation matrix
btb.nona <- na.omit(btb)
cov(btb.nona[, 5:9])
cor(btb.nona[, 5:9])
# the covariance and correlation matrices are not observed obvious patterns
```

### Missing Data Exploration
```{r}
#summarizing number of non-NA observations at each occasion
measurement_counts <- btb.long %>%
  group_by(occasion) %>%
  summarise(n = sum(!is.na(score)))

measurement_counts
#48% of data is missing 
```

```{r}
#summarize missing data per group
measurement_counts2 <- btb.long %>%
  group_by(treatment, occasion) %>%
  summarise(n = sum(is.na(score)), .groups = "drop")

measurement_counts2_wide <- measurement_counts2 %>%
  pivot_wider(names_from = treatment, values_from = n) %>%
  mutate(Total = TAU + BtheB)

measurement_counts2_wide
```

```{r}
library(mice)
sapply(btb.long, function(x) sum(is.na(x)))

btb %>%
  dplyr::select(-id, -drug, -length, -treatment) %>%
  md.pattern()

# missing data is monotone, arising from dropout, assume MAR, use likelihood methods like in class
```

### Methods
Model Selection Process:

- no need to include treatment because it is a randomized trial

```{r}
# random intercept
lme.intp <- lme(score ~ occasion + drug + length + occasion:treatment, 
                random = ~ 1 | id, data = btb.long, na.action = na.omit)
#summary(lme.intp)

# random intercept and slope
lme.slope <- lme(score ~ occasion + drug + length + occasion:treatment, 
                 random = ~ occasion | id, data = btb.long, na.action = na.omit)
#summary(lme.slope)

# compare using likelihood ratio test
lme.intp.ml <- lme(score ~ occasion + drug + length + occasion:treatment, 
                random = ~ 1 | id, method = "ML",
                data = btb.long, na.action = na.omit)
lme.slope.ml <- lme(score ~ occasion + drug + length + occasion:treatment, 
                 random = ~ occasion | id, method = "ML",
                 data = btb.long, na.action = na.omit)
anova(lme.intp.ml, lme.slope.ml) # lme.intp.ml is better

# drop drug for the intercept model since not significant
lme.intp1 <- lme(score ~ occasion + length + occasion:treatment, random = ~ 1 | id,
                data = btb.long, na.action = na.omit)

lme.intp1.ml <- lme(score ~ occasion + length + occasion:treatment, 
                random = ~ 1 | id, method = "ML",
                data = btb.long, na.action = na.omit)
anova(lme.intp1.ml, lme.intp.ml)
```

```{r}
# AIC and BIC function for model comparison
outAIC <- function(x){
  sumx <- summary(x)
  out <- c(sumx$AIC, sumx$BIC)
  names(out) <- c("AIC", "BIC")
  out
}

allaic <- rbind(
  outAIC(lme.intp),
  outAIC(lme.slope),
  outAIC(lme.intp1)
)
rownames(allaic) <- c("lme.intp", "lme.slope", "lme.intp1")
allaic
#AIC is similar for all models but BIC is lowest for lme.intp1 (which is also more parsimonious)
#so we go with that model over the others
```

Create a binary indicator of pre- and post-treatment: post
```{r}
btb.long <- btb.long %>%
  group_by(id) %>%
  mutate(time = row_number() - 1, # time: 0 1 2 3 4
         post = ifelse(time > 0, 1, 0)) %>%
  ungroup()
```


```{r}
# random intercept
mod1.intp <- lme(score ~ post + drug + length + post:treatment,
                 random = ~ 1 | id, data = btb.long, na.action = na.omit)
#summary(mod1.intp)

# random intercept and slope model
mod1.slope <- lme(score ~ post + drug + length + post:treatment, 
                  random = ~ post | id, data = btb.long, na.action = na.omit)
#summary(mod1.slope)

# compare using likelihood ratio test
mod1.intp.ml <- lme(score ~ post + drug + length + post:treatment, random = ~ 1 | id, 
                    method = "ML", data = btb.long, na.action = na.omit)
mod1.slope.ml <- lme(score ~ post + drug + length + post:treatment, random = ~ post | id, 
                    method = "ML", data = btb.long, na.action = na.omit)
anova(mod1.intp.ml, mod1.slope.ml)
#since p-value <0.0001, the random intercept and slope model is significantly better

mod1.slope1 <- lme(score ~ post + length + post:treatment, 
                   random = ~ post | id, data = btb.long, na.action = na.omit)
```

```{r}
allaic <- rbind(
  outAIC(mod1.slope1), # final model
  outAIC(mod1.slope),
  outAIC(mod1.intp),
  outAIC(lme.intp1),
  outAIC(lme.intp)
)
rownames(allaic) <- c("mod1.slope1", "mod1.slope", "mod1.intp", "lme.intp1", "lme.intp")
allaic
#BIC is smallest for random slope and intercept model when time is divided as pre and post without drug: mod1.slope1
```

Final Model:
$$Y_{ij} = \beta0 + \beta1 \text{ Post}_{ij} + \beta2 \text{ Length}_i + \beta3 \text{ Post}_{ij} \times \text{Treatment}_{i} + b_{1i} + b_{2i} \text{ Post}_{ij} + \epsilon_{ij}$$

```{r}
# exclude drug because it is not significant in all models (choose the parsimonious model)

# final model
mod1.slope1 <- lme(score ~ post + length + post:treatment, 
                  random = ~ post | id, data = btb.long, na.action = na.omit)
summary(mod1.slope1)

summary_df <- broom.mixed::tidy(mod1.slope1, effect = "fixed", conf.int = TRUE)
summary_df %>%
  kable(format = "html", digits = 2, caption = "Fixed Effects of the LME Model") %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)
```


```{r}
G <- getVarCov(mod1.slope1) # G matrix
G
vcov <- mod1.slope1$varFix # covariance of fixed effects (beta) estimates
vcov
```

```{r}
mod_summary <- coef(summary(mod1.slope1))

# follow-up compared to baseline
# 95% CI for TAU group 
mod_summary["post", "Value"] + c(-1, 1)*qnorm(0.975)*mod_summary["post", "Std.Error"]

# 95% CI for BtheB group
(mod_summary[2,1] + mod_summary[4,1]) + 
  c(-1, 1)*qnorm(0.975)*sqrt(vcov[2,2] + vcov[4,4] + 2*vcov[2,4])

# 95% quintile of the random slope with the population effect as the center
# to understand how wide (or narrow) the variance of the random effects are
mod_summary[1,1] + c(-1,1)*qnorm(0.975)*sqrt(G[1,1]) # random intp

mod_summary[4,1] + c(-1,1)*qnorm(0.975)*sqrt(G[2,2]) # random slope
```


### Model Diagnostics - Assumption
Normality assumption check for stage-one residuals:

```{r}
btb.long <- na.omit(btb.long)

# standardized stage-one residuals
rhat <- resid(mod1.slope1, type = "normalized")
head(rhat)

# standardized stage-one residuals by "hand"
condmean <- predict(mod1.slope1) # conditional means
y <- btb.long$score
stg1r <- y - condmean 

estsigma2 <- sigma(mod1.slope1)^2
estsigmamat <- estsigma2 * diag(dim(btb.long)[1])
L <- chol(estsigmamat)
stg1rstar <- solve(L) %*% stg1r
head(stg1rstar) # they matched

# comparing raw stage-one residuals and standardized residuals
rtype <- c(rep("Raw", length(stg1r)), rep("Standardized", length(stg1r)))
resid <- c(stg1r, stg1rstar)
stg1resids <- as.data.frame(cbind(rtype, as.numeric(resid)))

ggplot(stg1resids, aes(x = resid, fill = rtype)) +                    
  geom_histogram(position = "identity", alpha = 0.5, bins = 50) + 
  labs(y = "Count", x = "Residuals", fill = "Type") +
  ggtitle("Histogram of Comparing Raw Stage-One Residuals 
          and Standardized Residuals") + 
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

# qq plot of standardized residuals
qqnorm(rhat, pch = 1, main = "Normal Q-Q Plot of Stage-One Standardized Residuals")
qqline(rhat, col = "steelblue", lwd = 2)

# Plot of standardized residuals against predicted mean
yhat <- predict(mod1.slope1)
plot(y = rhat, x = yhat, main = "Standardized Residuals vs Predicted Mean")
```


Normality assumption check for random effects:
```{r}
par(mfrow = c(1, 2))

b1hat <- ranef(mod1.slope1)[,1]
b2hat <- ranef(mod1.slope1)[,2]

# qq plot of random effects
qqnorm(b1hat, pch=1, main = "Normal Q-Q Plot of b1")
qqline(b1hat, col = "steelblue", lwd = 2)

qqnorm(b2hat, pch=1, main = "Normal Q-Q Plot of b2")
qqline(b2hat, col = "steelblue", lwd = 2)

# histogram of random effects
ranef(mod1.slope1) %>%
  pivot_longer(cols = c("(Intercept)", "post"),
               names_to = "ranefs",
               values_to = "estimates") %>%
  ggplot(aes(x = estimates)) + 
  geom_histogram(position = "identity", alpha = 0.5, bins = 50, fill = "orange") +
  facet_grid(~ ranefs)
# a little bit skewed, but as long as it's not overly skewed, it is fine
```


